# Training parameters
prior_preservation: "True"
prior_loss_weight: 1.0
train_batch_size: 1
gradient_accumulation_steps: 1
learning_rate: 0.000005
lr_scheduler: "constant"
lr_warmup_steps: 0
num_class_images: 200
max_train_steps: 800